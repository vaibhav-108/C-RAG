{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65522ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Vaibhav_PC\\GenerativeAI\\GI\\Advance_RAG\\Campus_RAG\\CRAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List,TypedDict\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader,PyPDFDirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import  RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "from langgraph.graph import START,StateGraph,END\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67077f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENROUTER_API_KEY=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "tavily_api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENROUTER_API_KEY\"]=OPENROUTER_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"]=tavily_api_key\n",
    "\n",
    "model= ChatOpenAI( base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    model= \"upstage/solar-pro-3:free\"\n",
    ")\n",
    "model.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = (\n",
    "    PyPDFLoader(\"./documents/book1.pdf\").load()\n",
    "    + PyPDFLoader(\"./documents/book2.pdf\").load()\n",
    "    + PyPDFLoader(\"./documents/book3.pdf\").load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150).split_documents(docs)\n",
    "for d in chunks:\n",
    "    d.page_content = d.page_content.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80916",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPPER_TH = 0.7\n",
    "LOWER_TH = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee00dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "\n",
    "    question: str\n",
    "    docs: List[Document]\n",
    "\n",
    "    good_docs: List[Document]\n",
    "    verdict: str\n",
    "    reason: str\n",
    "\n",
    "    strips: List[str]\n",
    "    kept_strips: List[str]\n",
    "    refined_context: str\n",
    "\n",
    "    web_docs: List[Document]  \n",
    "    web_query: str #✅ added\n",
    "\n",
    "    \n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929aff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve(state: State) -> State:\n",
    "    q = state[\"question\"]\n",
    "    return {\"docs\": retriever.invoke(q)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a92491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Score-based doc evaluator\n",
    "# -----------------------------\n",
    "class DocEvalScore(BaseModel):\n",
    "    score: float\n",
    "    reason: str\n",
    "\n",
    "doc_eval_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a strict retrieval evaluator for RAG.\\n\"\n",
    "            \"You will be given ONE retrieved chunk and a question.\\n\"\n",
    "            \"Return a relevance score in [0.0, 1.0].\\n\"\n",
    "            \"- 1.0: chunk alone is sufficient to answer fully/mostly\\n\"\n",
    "            \"- 0.0: chunk is irrelevant\\n\"\n",
    "            \"Be conservative with high scores.\\n\"\n",
    "            \"Also return a short reason.\\n\"\n",
    "            \"Output JSON only.\",\n",
    "        ),\n",
    "        (\"human\", \"Question: {question}\\n\\nChunk:\\n{chunk}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "doc_eval_chain = doc_eval_prompt | model.with_structured_output(DocEvalScore)\n",
    "\n",
    "def eval_each_doc_node(state: State) -> State:\n",
    "\n",
    "    q = state[\"question\"]\n",
    "    \n",
    "    scores: List[float] = []\n",
    "    reasons: List[str] = []\n",
    "    good: List[Document] = []\n",
    "\n",
    "    for d in state[\"docs\"]:\n",
    "        out = doc_eval_chain.invoke({\"question\": q, \"chunk\": d.page_content})\n",
    "        scores.append(out.score)\n",
    "        reasons.append(out.reason)\n",
    "\n",
    "        # 5) for CORRECT case we will refine only docs with score > LOWER_TH\n",
    "        if out.score > LOWER_TH:\n",
    "            good.append(d)\n",
    "\n",
    "    # 2) CORRECT if at least one doc > UPPER_TH\n",
    "    if any(s > UPPER_TH for s in scores):\n",
    "        return {\n",
    "            \"good_docs\": good,\n",
    "            \"verdict\": \"CORRECT\",\n",
    "            \"reason\": f\"At least one retrieved chunk scored > {UPPER_TH}.\",\n",
    "        }\n",
    "\n",
    "    # 3) INCORRECT if all docs < LOWER_TH\n",
    "    if len(scores) > 0 and all(s < LOWER_TH for s in scores):\n",
    "        why = \"No chunk was sufficient.\"\n",
    "        return {\n",
    "            \"good_docs\": [],\n",
    "            \"verdict\": \"INCORRECT\",\n",
    "            \"reason\": f\"All retrieved chunks scored < {LOWER_TH}. {why}\",\n",
    "        }\n",
    "\n",
    "    # 4) Anything in between => AMBIGUOUS\n",
    "    why = \"Mixed relevance signals.\"\n",
    "    return {\n",
    "        \"good_docs\": good,\n",
    "        \"verdict\": \"AMBIGUOUS\",\n",
    "        \"reason\": f\"No chunk scored > {UPPER_TH}, but not all were < {LOWER_TH}. {why}\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Sentence-level DECOMPOSER\n",
    "# -----------------------------\n",
    "def decompose_to_sentences(text: str) -> List[str]:\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "    return [s.strip() for s in sentences if len(s.strip()) > 20]\n",
    "\n",
    "# -----------------------------\n",
    "# FILTER (LLM judge)\n",
    "# -----------------------------\n",
    "class KeepOrDrop(BaseModel):\n",
    "    keep: bool\n",
    "\n",
    "filter_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a strict relevance filter.\\n\"\n",
    "            \"Return keep=true only if the sentence directly helps answer the question.\\n\"\n",
    "            \"Use ONLY the sentence. Output JSON only.\",\n",
    "        ),\n",
    "        (\"human\", \"Question: {question}\\n\\nSentence:\\n{sentence}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "filter_chain = filter_prompt | model.with_structured_output(KeepOrDrop)\n",
    "\n",
    "# -----------------------------\n",
    "# REFINING (Decompose -> Filter -> Recompose)\n",
    "# -----------------------------\n",
    "def refine(state: State) -> State:\n",
    "    q = state[\"question\"]\n",
    "\n",
    "    if state.get(\"verdict\") == \"CORRECT\":\n",
    "        context = \"\\n\\n\".join(d.page_content for d in state[\"good_docs\"]).strip()\n",
    "    else:\n",
    "        context = \"\\n\\n\".join(d.page_content for d in state[\"web_docs\"]).strip()\n",
    "        \n",
    "\n",
    "    strips = decompose_to_sentences(context)\n",
    " \n",
    "    kept: List[str] = []\n",
    "    for s in strips:\n",
    "        if filter_chain.invoke({\"question\": q, \"sentence\": s}).keep:\n",
    "            kept.append(s)\n",
    "\n",
    "    refined_context = \"\\n\".join(kept).strip()\n",
    "\n",
    "    return {\n",
    "        \"strips\": strips,\n",
    "        \"kept_strips\": kept,\n",
    "        \"refined_context\": refined_context,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f59f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebQuerry(BaseModel):\n",
    "    query:str\n",
    "    \n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Rewrite the user question into a web search query composed of keywords.\\n\"\n",
    "            \"Rules:\\n\"\n",
    "            \"- Keep it short (6–14 words).\\n\"\n",
    "            \"- If the question implies recency (e.g., recent/latest/last week/last month), add a constraint like (last 30 days).\\n\"\n",
    "            \"- Do NOT answer the question.\\n\"\n",
    "            \"- Return JSON with a single key: query\",\n",
    "        ),\n",
    "        (\"human\", \"Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rewrite_chain = rewrite_prompt | model.with_structured_output(WebQuerry)\n",
    "\n",
    "def rewrite_query(state:State) -> State:\n",
    "    out = rewrite_chain.invoke({'question':state['question']})\n",
    "    return {'web_query': out.query}\n",
    "\n",
    "tavily = TavilySearchResults(max_results=5,\n",
    "                            TAVILY_API_KEY=tavily_api_key)\n",
    "\n",
    "def web_search_node(state: State) -> State:\n",
    "\n",
    "    q = state.get('web_query') or state['question']  # fallback if query empty\n",
    "    results = tavily.invoke({\"query\": q})  # no knowledge selection\n",
    "\n",
    "\n",
    "    web_docs = []\n",
    "    for r in results or []:\n",
    "\n",
    "        title = r.get(\"title\", \"\")\n",
    "        url = r.get(\"url\", \"\")\n",
    "        content = r.get(\"content\", \"\") or r.get(\"snippet\", \"\")\n",
    "        \n",
    "        text = f\"TITLE: {title}\\nURL: {url}\\nCONTENT:\\n{content}\"\n",
    "\n",
    "        web_docs.append(Document(page_content=text, metadata={\"url\": url, \"title\": title}))\n",
    "\n",
    "    return {\"web_docs\": web_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434caa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful ML tutor. Answer ONLY using the provided context.\\n\"\n",
    "            \"If the context is empty or insufficient, say: 'I don't know.'\",\n",
    "        ),\n",
    "        (\"human\", \"Question: {question}\\n\\nRefined context:\\n{refined_context}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def generate(state: State) -> State:\n",
    "    out = (answer_prompt | model).invoke(\n",
    "        {\"question\": state[\"question\"], \"refined_context\": state[\"refined_context\"]}\n",
    "    )\n",
    "    return {\"answer\": out.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Routing\n",
    "# CORRECT => refine\n",
    "# INCORRECT / AMBIGUOUS => rewrite -> web_search -> refine -> generate\n",
    "# -----------------------------\n",
    "def route_after_eval(state: State) -> str:\n",
    "    if state[\"verdict\"] == \"CORRECT\":\n",
    "        return \"refine\"\n",
    "    else:\n",
    "        return \"rewrite_query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecee597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Graph\n",
    "# -----------------------------\n",
    "g = StateGraph(State)\n",
    "\n",
    "g.add_node(\"retrieve\", retrieve)\n",
    "g.add_node(\"eval_each_doc\", eval_each_doc_node)\n",
    "\n",
    "g.add_node('rewrite_query', rewrite_query)\n",
    "g.add_node(\"web_search\", web_search_node)\n",
    "\n",
    "g.add_node(\"refine\", refine)          # uses verdict to pick good_docs vs web_docs\n",
    "g.add_node(\"generate\", generate)\n",
    "\n",
    "\n",
    "# flow\n",
    "g.add_edge(START, \"retrieve\")\n",
    "g.add_edge(\"retrieve\", \"eval_each_doc\")\n",
    "\n",
    "# route after evaluation\n",
    "g.add_conditional_edges(\n",
    "    \"eval_each_doc\",\n",
    "    route_after_eval,\n",
    "    {\n",
    "        \"refine\": \"refine\",          # CORRECT -> refine (good_docs)\n",
    "        \"rewrite_query\": \"rewrite_query\",  # INCORRECT -> web_search\n",
    "        \n",
    "    },\n",
    ")\n",
    "\n",
    "# Incorrect path : rewrite_query -> web_search -> refine -> generate\n",
    "g.add_edge('rewrite_query','web_search')\n",
    "g.add_edge(\"web_search\", \"refine\")   \n",
    "g.add_edge(\"refine\", \"generate\")      \n",
    "\n",
    "g.add_edge(\"generate\", END)\n",
    "\n",
    "\n",
    "app = g.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c1290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a067bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c80baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09dc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
